{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "018af251-ebd0-4b76-9d20-d298624b0ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "305c4b3c-f66d-431d-a10b-18378ac18c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV created: C:/Users/mrmik/OneDrive/Desktop/route_data.csv\n"
     ]
    }
   ],
   "source": [
    "input_file = 'C:/Users/mrmik/~/.rc-cli/data/model_build_inputs/route_data.json'\n",
    "output_file = 'C:/Users/mrmik/OneDrive/Desktop/route_data.csv'\n",
    "\n",
    "# Open files\n",
    "with open(input_file, 'r') as infile, open(output_file, 'w', newline='') as outfile:\n",
    "    writer = None\n",
    "\n",
    "    for line in infile:\n",
    "        data = json.loads(line)  # Parse each line\n",
    "        if writer is None:\n",
    "            # Initialize CSV writer with the first object's keys as headers\n",
    "            writer = csv.DictWriter(outfile, fieldnames=data.keys())\n",
    "            writer.writeheader()\n",
    "        writer.writerow(data)\n",
    "\n",
    "print(f\"CSV created: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "869b5dae-0a08-4d03-b0fe-dd4648c261ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned CSV created: C:/Users/mrmik/OneDrive/Desktop/route_data_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "input_file = 'C:/Users/mrmik/~/.rc-cli/data/model_build_inputs/route_data.json'\n",
    "output_file = 'C:/Users/mrmik/OneDrive/Desktop/route_data_cleaned.csv'\n",
    "\n",
    "# Function to flatten nested JSON (if applicable)\n",
    "def flatten_json(y, prefix=''):\n",
    "    flattened = {}\n",
    "    for key, value in y.items():\n",
    "        if isinstance(value, dict):\n",
    "            # Recursively flatten nested dictionaries\n",
    "            flattened.update(flatten_json(value, prefix + key + '_'))\n",
    "        else:\n",
    "            flattened[prefix + key] = value\n",
    "    return flattened\n",
    "\n",
    "# Open files\n",
    "with open(input_file, 'r') as infile, open(output_file, 'w', newline='', encoding='utf-8') as outfile:\n",
    "    writer = None\n",
    "\n",
    "    for line_number, line in enumerate(infile, start=1):\n",
    "        try:\n",
    "            # Parse each line of JSON\n",
    "            data = json.loads(line.strip())\n",
    "            # Flatten nested JSON if necessary\n",
    "            data = flatten_json(data)\n",
    "\n",
    "            if writer is None:\n",
    "                # Initialize CSV writer with the first object's keys as headers\n",
    "                writer = csv.DictWriter(outfile, fieldnames=data.keys())\n",
    "                writer.writeheader()\n",
    "\n",
    "            # Write data to CSV\n",
    "            writer.writerow(data)\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing line {line_number}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error on line {line_number}: {e}\")\n",
    "\n",
    "print(f\"Cleaned CSV created: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc655fb-af14-42da-828e-666e533d7d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "input_file = 'C:/Users/mrmik/~/.rc-cli/data/model_build_inputs/route_data.json'\n",
    "output_file = 'C:/Users/mrmik/OneDrive/Desktop/route_data_cleaned.csv'\n",
    "\n",
    "# Function to flatten nested JSON\n",
    "def flatten_json(y, prefix=''):\n",
    "    flattened = {}\n",
    "    for key, value in y.items():\n",
    "        if isinstance(value, dict):\n",
    "            flattened.update(flatten_json(value, prefix + key + '_'))\n",
    "        else:\n",
    "            flattened[prefix + key] = value\n",
    "    return flattened\n",
    "\n",
    "# Open files\n",
    "with open(input_file, 'r') as infile, open(output_file, 'w', newline='', encoding='utf-8') as outfile:\n",
    "    writer = None\n",
    "\n",
    "    for line_number, line in enumerate(infile, start=1):\n",
    "        print(f\"Line {line_number}: {line.strip()}\")  # Debug: Inspect input\n",
    "        try:\n",
    "            data = json.loads(line.strip())\n",
    "            data = flatten_json(data)\n",
    "            print(f\"Processed Data for Line {line_number}: {data}\")  # Debug: Inspect processed data\n",
    "\n",
    "            if writer is None:\n",
    "                writer = csv.DictWriter(outfile, fieldnames=data.keys())\n",
    "                writer.writeheader()\n",
    "\n",
    "            writer.writerow(data)\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing line {line_number}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error on line {line_number}: {e}\")\n",
    "\n",
    "print(f\"CSV created: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20bfe8aa-ee26-436b-8c2a-78dc7090369c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The JSON format is not as expected (list of dictionaries). Please check the structure.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "# Correct file path (replace ~ with the actual user directory if needed)\n",
    "file_path = r\"C:\\Users\\mrmik\\MIT_amazon_data\\.rc-cli\\data\\model_build_inputs\\route_data.json\"\n",
    "\n",
    "# Load the JSON file\n",
    "try:\n",
    "    with open(file_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    # Specify the CSV output file\n",
    "    csv_file = 'output_data.csv'\n",
    "\n",
    "    # Check if the JSON file contains a list of dictionaries\n",
    "    if isinstance(data, list) and isinstance(data[0], dict):\n",
    "        # Writing JSON to CSV\n",
    "        with open(csv_file, mode='w', newline='') as file:\n",
    "            writer = csv.DictWriter(file, fieldnames=data[0].keys())\n",
    "            writer.writeheader()  # Write header row\n",
    "            writer.writerows(data)\n",
    "\n",
    "        print(f\"CSV file '{csv_file}' created successfully.\")\n",
    "    else:\n",
    "        print(\"The JSON format is not as expected (list of dictionaries). Please check the structure.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {file_path}. Please check the path.\")\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"Error decoding JSON from the file: {file_path}. Ensure it is a valid JSON file.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6400353-18d8-484e-b72a-3422069ffd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'output_data.csv' created successfully.\n"
     ]
    }
   ],
   "source": [
    "file_path = r\"C:\\Users\\mrmik\\MIT_amazon_data\\.rc-cli\\data\\model_build_inputs\\route_data.json\"\n",
    "\n",
    "# Open and load the JSON file\n",
    "with open(file_path, 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Handle different JSON formats\n",
    "if isinstance(data, list):  # Already a list of dictionaries\n",
    "    json_data = data\n",
    "elif isinstance(data, dict):  # JSON is a dictionary\n",
    "    # Check for nested lists\n",
    "    for key, value in data.items():\n",
    "        if isinstance(value, list):\n",
    "            json_data = value\n",
    "            break\n",
    "    else:\n",
    "        # Single dictionary case\n",
    "        json_data = [data]  # Convert single dictionary to a list\n",
    "else:\n",
    "    raise ValueError(\"Unsupported JSON format.\")\n",
    "\n",
    "# Write to CSV\n",
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=json_data[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(json_data)\n",
    "\n",
    "print(f\"CSV file '{csv_file}' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "288459c0-4aea-4cee-acca-73ede924442f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated f-string literal (detected at line 53) (3513506471.py, line 53)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[40], line 53\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(f\"Error decoding JSON from\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated f-string literal (detected at line 53)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Corrected file path (use raw string or double backslashes)\n",
    "file_path = r\"C:\\Users\\mrmik\\.rc-cli\\data\\model_build_inputs\\route_data.json\"\n",
    "\n",
    "# Load the JSON file\n",
    "try:\n",
    "    with open(file_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    # Flatten the data if necessary\n",
    "    def flatten_json(y):\n",
    "        out = {}\n",
    "\n",
    "        def flatten(x, name=''):\n",
    "            if type(x) is dict:\n",
    "                for a in x:\n",
    "                    flatten(x[a], name + a + '_')\n",
    "            elif type(x) is list:\n",
    "                i = 0\n",
    "                for a in x:\n",
    "                    flatten(a, name + str(i) + '_')\n",
    "                    i += 1\n",
    "            else:\n",
    "                out[name[:-1]] = x\n",
    "\n",
    "        flatten(y)\n",
    "        return out\n",
    "\n",
    "    json_data = [flatten_json(item) for item in data] if isinstance(data, list) else [flatten_json(data)]\n",
    "\n",
    "    # Print current working directory for file location\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "    # Set the output file path to your working directory\n",
    "    csv_file = r'C:\\Users\\mrmik\\OneDrive\\Desktop\\NSS\\Python\\Capstone\\output_data.csv'\n",
    "    with open(csv_file, mode='w', newline='') as file:\n",
    "        # Get the fieldnames dynamically (column headers) from the first record\n",
    "        writer = csv.DictWriter(file, fieldnames=json_data[0].keys())\n",
    "        writer.writeheader()\n",
    "\n",
    "        # Write each dictionary as a row\n",
    "        for record in json_data:\n",
    "            writer.writerow(record)\n",
    "\n",
    "    print(f\"CSV file '{csv_file}' created successfully.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {file_path}. Please check the path.\")\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"Error decoding JSON from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5634c2cb-51d0-4269-bf52-d03e06f7fd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\mrmik\\OneDrive\\Desktop\\NSS\\Python\\Capstone\n",
      "CSV file 'C:\\Users\\mrmik\\OneDrive\\Desktop\\NSS\\Python\\Capstone\\output_data.csv' created successfully.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Corrected file path (use raw string or double backslashes)\n",
    "file_path = r\"C:\\Users\\mrmik\\MIT_amazon_data\\.rc-cli\\data\\model_build_inputs\\route_data.json\"\n",
    "\n",
    "# Load the JSON file\n",
    "try:\n",
    "    with open(file_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    # Flatten the data if necessary\n",
    "    def flatten_json(y):\n",
    "        out = {}\n",
    "\n",
    "        def flatten(x, name=''):\n",
    "            if type(x) is dict:\n",
    "                for a in x:\n",
    "                    flatten(x[a], name + a + '_')\n",
    "            elif type(x) is list:\n",
    "                i = 0\n",
    "                for a in x:\n",
    "                    flatten(a, name + str(i) + '_')\n",
    "                    i += 1\n",
    "            else:\n",
    "                out[name[:-1]] = x\n",
    "\n",
    "        flatten(y)\n",
    "        return out\n",
    "\n",
    "    json_data = [flatten_json(item) for item in data] if isinstance(data, list) else [flatten_json(data)]\n",
    "\n",
    "    # Print current working directory for file location\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "    # Set the output file path to your working directory\n",
    "    csv_file = r'C:\\Users\\mrmik\\OneDrive\\Desktop\\NSS\\Python\\Capstone\\output_data.csv'\n",
    "    with open(csv_file, mode='w', newline='') as file:\n",
    "        # Get the fieldnames dynamically (column headers) from the first record\n",
    "        writer = csv.DictWriter(file, fieldnames=json_data[0].keys())\n",
    "        writer.writeheader()\n",
    "\n",
    "        # Write each dictionary as a row\n",
    "        for record in json_data:\n",
    "            writer.writerow(record)\n",
    "\n",
    "    print(f\"CSV file '{csv_file}' created successfully.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {file_path}. Please check the path.\")\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"Error decoding JSON from the file: {file_path}. Ensure it is a valid JSON file.\")\n",
    "except ValueError as ve:\n",
    "    print(f\"ValueError: {ve}\")\n",
    "except PermissionError:\n",
    "    print(f\"PermissionError: Unable to write to the file '{csv_file}'. Please check your permissions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "90040291-53b3-4fe6-bd27-c061abd7caa0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'notebook.services'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnotebook\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConfigManager\n\u001b[0;32m      3\u001b[0m cm \u001b[38;5;241m=\u001b[39m ConfigManager()\n\u001b[0;32m      4\u001b[0m cm\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnotebook\u001b[39m\u001b[38;5;124m'\u001b[39m, {\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNotebookApp\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miopub_data_rate_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m10000000\u001b[39m\n\u001b[0;32m      7\u001b[0m     }\n\u001b[0;32m      8\u001b[0m })\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'notebook.services'"
     ]
    }
   ],
   "source": [
    "from notebook.services.config import ConfigManager\n",
    "\n",
    "cm = ConfigManager()\n",
    "cm.update('notebook', {\n",
    "    \"NotebookApp\": {\n",
    "        \"iopub_data_rate_limit\": 10000000\n",
    "    }\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c740123-0d42-4cb3-b797-cc180085119b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Corrected file path (use raw string or double backslashes)\n",
    "file_path = r\"C:\\Users\\mrmik\\MIT_amazon_data\\.rc-cli\\data\\model_build_inputs\\route_data.json\"\n",
    "\n",
    "# Load the JSON file\n",
    "try:\n",
    "    with open(file_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    # Flatten the data if necessary\n",
    "    def flatten_json(y):\n",
    "        out = {}\n",
    "\n",
    "        def flatten(x, name=''):\n",
    "            if type(x) is dict:\n",
    "                for a in x:\n",
    "                    flatten(x[a], name + a + '_')\n",
    "            elif type(x) is list:\n",
    "                i = 0\n",
    "                for a in x:\n",
    "                    flatten(a, name + str(i) + '_')\n",
    "                    i += 1\n",
    "            else:\n",
    "                out[name[:-1]] = x\n",
    "\n",
    "        flatten(y)\n",
    "        return out\n",
    "\n",
    "    json_data = [flatten_json(item) for item in data] if isinstance(data, list) else [flatten_json(data)]\n",
    "\n",
    "    # Debug: Print the structure of the json_data\n",
    "    print(\"Flattened JSON data:\")\n",
    "    for item in json_data:\n",
    "        print(item)\n",
    "\n",
    "    # Print current working directory for file location\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "    # Set the output file path to your working directory\n",
    "    csv_file = r'C:\\Users\\mrmik\\OneDrive\\Desktop\\NSS\\Python\\Capstone\\output_data.csv'\n",
    "    with open(csv_file, mode='w', newline='') as file:\n",
    "        # Get the fieldnames dynamically (column headers) from the first record\n",
    "        writer = csv.DictWriter(file, fieldnames=json_data[0].keys())\n",
    "        writer.writeheader()\n",
    "\n",
    "        # Write each dictionary as a row\n",
    "        for record in json_data:\n",
    "            writer.writerow(record)\n",
    "\n",
    "    print(f\"CSV file '{csv_file}' created successfully.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {file_path}. Please check the path.\")\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"Error decoding JSON from the file: {file_path}. Ensure it is a valid JSON file.\")\n",
    "except ValueError as ve:\n",
    "    print(f\"ValueError: {ve}\")\n",
    "except PermissionError:\n",
    "    print(f\"PermissionError: Unable to write to the file '{csv_file}'. Please check your permissions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c292b0c-7c6f-446f-b12a-f24233080be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import psycopg2\n",
    "\n",
    "with open('route_data.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Connect to PostgreSQL\n",
    "conn = psycopg2.connect(\n",
    "    dbname='PostgreSQL_16',\n",
    "    user='postgres',\n",
    "    host='localhost'\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Insert JSON data\n",
    "for item in data:\n",
    "    cur.execute(\n",
    "        \"INSERT INTO my_table (data) VALUES (%s::jsonb)\",\n",
    "        [json.dumps(item)]\n",
    "    )\n",
    "\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ad917d1-2e0c-4d04-86df-46b8a94e6fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data loaded successfully!\n",
      "An error occurred: \"Key 'Stops' not found. If specifying a record_path, all elements of data should have the path.\"\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "\n",
    "# Define the file path\n",
    "file_path = 'C:/Users/mrmik/MIT_amazon_data/.rc-cli/data/model_build_inputs/route_data.json'\n",
    "\n",
    "try:\n",
    "    with open(file_path) as file:\n",
    "        data = json.load(file)\n",
    "    print(\"JSON data loaded successfully!\")\n",
    "\n",
    "    # Normalize the route data\n",
    "    routes = json_normalize(data, sep='_')\n",
    "\n",
    "    # Normalize the stops and packages data\n",
    "    stops = json_normalize(data, 'Stops', ['Route ID', 'Station code', 'Date'], sep='_')\n",
    "    packages = json_normalize(data, 'Stops.Packages', ['Route ID', 'Stops.Stop ID'], sep='_')\n",
    "\n",
    "    # Display the dataframes\n",
    "    print(routes.head())\n",
    "    print(stops.head())\n",
    "    print(packages.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {file_path}\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error decoding JSON: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075079d1-de92-4ccf-8817-6502fed84cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Connect to PostgreSQL\n",
    "conn = psycopg2.connect(\n",
    "    dbname='lastmile_data',\n",
    "    user='postgres',\n",
    "    host='localhost'\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Insert routes data\n",
    "for _, row in routes.iterrows():\n",
    "    cur.execute(\n",
    "        \"INSERT INTO routes (route_id, station_code, date, departure_time, executor_capacity, observed_sequence, route_score) VALUES (%s, %s, %s, %s, %s, %s, %s)\",\n",
    "        (row['Route ID'], row['Station code'], row['Date'], row['Departure time'], row['Executor capacity'], row['Observed sequence'], row['Route score'])\n",
    "    )\n",
    "\n",
    "# Insert stops data\n",
    "for _, row in stops.iterrows():\n",
    "    cur.execute(\n",
    "        \"INSERT INTO stops (route_id, stop_id, latitude, longitude, type, zone_id, transit_time) VALUES (%s, %s, %s, %s, %s, %s, %s)\",\n",
    "        (row['Route ID'], row['Stop ID'], row['Latitude/longitude.lat'], row['Latitude/longitude.lon'], row['Type'], row['Zone ID'], row['Transit time'])\n",
    "    )\n",
    "\n",
    "# Insert packages data\n",
    "for _, row in packages.iterrows():\n",
    "    cur.execute(\n",
    "        \"INSERT INTO packages (route_id, stop_id, package_id, status, time_window_start, time_window_end, planned_service_time, dimensions_length, dimensions_width, dimensions_height) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\",\n",
    "        (row['Route ID'], row['Stop ID'], row['Package ID'], row['Status'], row['Time window.start'], row['Time window.end'], row['Planned service time'], row['Dimensions.length'], row['Dimensions.width'], row['Dimensions.height'])\n",
    "    )\n",
    "\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c892919-bad8-4b50-8d8f-5630d06f64ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data loaded successfully!\n",
      "An error occurred: \"Key 'Stops' not found. If specifying a record_path, all elements of data should have the path.\"\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "\n",
    "file_path = 'C:/Users/mrmik/MIT_amazon_data/.rc-cli/data/model_build_inputs/route_data.json'\n",
    "\n",
    "try:\n",
    "    with open(file_path) as file:\n",
    "        data = json.load(file)\n",
    "    print(\"JSON data loaded successfully!\")\n",
    "\n",
    "    routes = json_normalize(data, sep='_')\n",
    "    stops = json_normalize(data, 'Stops', ['Route ID', 'Station code', 'Date'], sep='_')\n",
    "    packages = json_normalize(data, 'Stops.Packages', ['Route ID', 'Stops.Stop ID'], sep='_')\n",
    "\n",
    "    # Print sample data\n",
    "    print(routes.head())\n",
    "    print(stops.head())\n",
    "    print(packages.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {file_path}\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error decoding JSON: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7b3708a-f6d2-4a26-b79e-c09055f960b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RouteID_00143bdd-0a6b-49ec-bb35-36593d303e77_station_code  \\\n",
      "0                                               DLA3          \n",
      "\n",
      "  RouteID_00143bdd-0a6b-49ec-bb35-36593d303e77_date_YYYY_MM_DD  \\\n",
      "0                                         2018-07-27             \n",
      "\n",
      "  RouteID_00143bdd-0a6b-49ec-bb35-36593d303e77_departure_time_utc  \\\n",
      "0                                           16:02:10                \n",
      "\n",
      "   RouteID_00143bdd-0a6b-49ec-bb35-36593d303e77_executor_capacity_cm3  \\\n",
      "0                                          3313071.0                    \n",
      "\n",
      "  RouteID_00143bdd-0a6b-49ec-bb35-36593d303e77_route_score  \\\n",
      "0                                               High         \n",
      "\n",
      "   RouteID_00143bdd-0a6b-49ec-bb35-36593d303e77_stops_AD_lat  \\\n",
      "0                                          34.099611           \n",
      "\n",
      "   RouteID_00143bdd-0a6b-49ec-bb35-36593d303e77_stops_AD_lng  \\\n",
      "0                                        -118.283062           \n",
      "\n",
      "  RouteID_00143bdd-0a6b-49ec-bb35-36593d303e77_stops_AD_type  \\\n",
      "0                                            Dropoff           \n",
      "\n",
      "  RouteID_00143bdd-0a6b-49ec-bb35-36593d303e77_stops_AD_zone_id  \\\n",
      "0                                            P-12.3C              \n",
      "\n",
      "   RouteID_00143bdd-0a6b-49ec-bb35-36593d303e77_stops_AF_lat  ...  \\\n",
      "0                                          34.101587          ...   \n",
      "\n",
      "   RouteID_fffd257c-3041-4736-be7a-5efea8af1173_stops_ZK_type  \\\n",
      "0                                            Dropoff            \n",
      "\n",
      "  RouteID_fffd257c-3041-4736-be7a-5efea8af1173_stops_ZK_zone_id  \\\n",
      "0                                            B-29.2C              \n",
      "\n",
      "  RouteID_fffd257c-3041-4736-be7a-5efea8af1173_stops_ZS_lat  \\\n",
      "0                                          42.200531          \n",
      "\n",
      "   RouteID_fffd257c-3041-4736-be7a-5efea8af1173_stops_ZS_lng  \\\n",
      "0                                         -88.375282           \n",
      "\n",
      "   RouteID_fffd257c-3041-4736-be7a-5efea8af1173_stops_ZS_type  \\\n",
      "0                                            Dropoff            \n",
      "\n",
      "  RouteID_fffd257c-3041-4736-be7a-5efea8af1173_stops_ZS_zone_id  \\\n",
      "0                                            B-29.2E              \n",
      "\n",
      "  RouteID_fffd257c-3041-4736-be7a-5efea8af1173_stops_ZX_lat  \\\n",
      "0                                          42.193048          \n",
      "\n",
      "   RouteID_fffd257c-3041-4736-be7a-5efea8af1173_stops_ZX_lng  \\\n",
      "0                                          -88.34287           \n",
      "\n",
      "   RouteID_fffd257c-3041-4736-be7a-5efea8af1173_stops_ZX_type  \\\n",
      "0                                            Dropoff            \n",
      "\n",
      "  RouteID_fffd257c-3041-4736-be7a-5efea8af1173_stops_ZX_zone_id  \n",
      "0                                                NaN             \n",
      "\n",
      "[1 rows x 3648668 columns]\n"
     ]
    }
   ],
   "source": [
    "print(routes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "536dca9f-1be4-4f34-9e69-d33077f89e2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (3970704269.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[7], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    route_data_sample = pd.read_json('C:\\Users\\mrmik\\MIT_amazon_data\\.rc-cli\\data\\model_build_inputs\\package_data.json')\u001b[0m\n\u001b[1;37m                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "route_data_sample = pd.read_json('C:\\Users\\mrmik\\MIT_amazon_data\\.rc-cli\\data\\model_build_inputs\\package_data.json')\n",
    "\n",
    "sample_data = route_data.sample(n=300)\n",
    "\n",
    "sample_data.to_csv('sample_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3040776-0076-4026-b1d3-6ba9acc50ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
